{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malicious URL Detection Jupyter Notebook\n",
    "Detect whether a given URL is malicious or benign using a machine learning model trained on your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load Dataset\n",
    "df = pd.read_csv('abc.dataset')  # Change path if needed\n",
    "df = df.dropna()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: URL Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature Engineering Functions\n",
    "def count_digits(url):\n",
    "    return sum(c.isdigit() for c in url)\n",
    "\n",
    "def count_special_chars(url):\n",
    "    return len(re.findall(r'[^a-zA-Z0-9]', url))\n",
    "\n",
    "def has_ip(url):\n",
    "    return int(bool(re.search(r'(?:[0-9]{1,3}\\.){3}[0-9]{1,3}', url)))\n",
    "\n",
    "def url_length(url):\n",
    "    return len(url)\n",
    "\n",
    "def count_subdomains(url):\n",
    "    return url.count(\".\")\n",
    "\n",
    "def suspicious_keywords(url):\n",
    "    keywords = ['login', 'verify', 'update', 'secure', 'account', 'webscr', 'banking', 'confirm']\n",
    "    return int(any(k in url.lower() for k in keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Add Features to DataFrame\n",
    "df['url_length'] = df['url'].apply(url_length)\n",
    "df['count_digits'] = df['url'].apply(count_digits)\n",
    "df['count_special'] = df['url'].apply(count_special_chars)\n",
    "df['has_ip'] = df['url'].apply(has_ip)\n",
    "df['count_subdomains'] = df['url'].apply(count_subdomains)\n",
    "df['suspicious_kw'] = df['url'].apply(suspicious_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Handcrafted Features with URL Text Features (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Prepare Features and Labels\n",
    "X_numeric = df[['url_length', 'count_digits', 'count_special', 'has_ip', 'count_subdomains', 'suspicious_kw']]\n",
    "y = df['type']  # e.g., 'malicious', 'benign', etc.\n",
    "\n",
    "# TF-IDF vectorizer for URL text\n",
    "tfidf = TfidfVectorizer(token_pattern=r'[a-zA-Z0-9]+', max_features=100)\n",
    "X_tfidf = tfidf.fit_transform(df['url'])\n",
    "\n",
    "# Combine numeric and text features\n",
    "from scipy.sparse import hstack\n",
    "X_all = hstack([X_numeric, X_tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Model Training\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Evaluation\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for User-Input URLs\n",
    "*Works even for URLs not seen during training!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Single URL Prediction Function\n",
    "def predict_url(url):\n",
    "    feats = [\n",
    "        url_length(url),\n",
    "        count_digits(url),\n",
    "        count_special_chars(url),\n",
    "        has_ip(url),\n",
    "        count_subdomains(url),\n",
    "        suspicious_keywords(url)\n",
    "    ]\n",
    "    X_num = np.array(feats).reshape(1, -1)\n",
    "    X_txt = tfidf.transform([url])\n",
    "    X_all = hstack([X_num, X_txt])\n",
    "    pred = clf.predict(X_all)\n",
    "    pred_prob = clf.predict_proba(X_all)\n",
    "    return pred[0], pred_prob.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Interactive Prediction\n",
    "user_url = input(\"Enter a URL to check if it's malicious or benign: \")\n",
    "label, confidence = predict_url(user_url)\n",
    "print(f\"Prediction: {label} (Confidence: {confidence:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model for Later Use (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(clf, 'url_detector_model.pkl')\n",
    "joblib.dump(tfidf, 'url_detector_tfidf.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}